# Week 2 - Logistic Regression as a Neural Network
## Vectorization
  - Removes the need for explicit 'for loops' when performing gradient decent - allowing algorithms to scale to very large datasets
  - this happens by using linear algebra, specifically the dot product 
  - runs ~300x faster
  - **Take Away:** Whenever possible, avoid explicit for loops!
  
